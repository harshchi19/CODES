# -*- coding: utf-8 -*-
"""Exp4&6_MLPipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AH520OgwA38Dq7wT532e8UDXo-hCUIyu

## **Ensemble Methods and Comparisons Dono kar diya**
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression
from pandas.plotting import scatter_matrix
import matplotlib.pyplot as plt
from sklearn.impute import SimpleImputer
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_squared_error ,r2_score , mean_absolute_error
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.datasets import load_iris,load_breast_cancer,load_wine,fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, roc_auc_score,classification_report

# ==============================
# Dataset Selection (Uncomment the desired dataset)
# ==============================

# 1. Breast Cancer Dataset (sklearn default):
breast_cancer = load_breast_cancer()
df = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)
labels = breast_cancer.target

# # 2. External Breast Cancer Dataset (CSV):
# df = pd.read_csv("breast-cancer.csv")
# labels = df['diagnosis']  # Assuming 'diagnosis' is the correct column name
# df = df.drop(['diagnosis'], axis=1)

# 3. Red Wine Quality Dataset:
df = pd.read_csv("winequality-red.csv", delimiter=",")
labels = df['quality']
df = df.drop(['quality'], axis=1)

# # 4. Housing Loan Approval Dataset:
# df = pd.read_csv("loan_sanction_train.csv")
# labels = df['Loan_Status']  # Assuming 'Loan_Status' is the target column
# labels = LabelEncoder().fit_transform(labels)  # Encode categorical target
# # Drop target column and preprocess categorical features
# df = df.drop(['Loan_Status'], axis=1)
# df = pd.get_dummies(df, drop_first=True)

# Exploratory Data Analysis for all 3
scatter_matrix(df.iloc[:, :5], figsize=(10, 10))  # Using first 5 features for visualization
plt.show()

sns.set(style="ticks", color_codes=True)
if 'species' in df.columns:
    sns.pairplot(df, hue='species')

plt.figure(figsize=(12, 10))
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, cmap='coolwarm')
plt.title('Feature Correlation Heatmap')
plt.show()

# ==============================
# Preprocessing (Applies to all datasets , Except Bahar wala Breast cancer)
# ==============================

# Impute missing values and scale features
imputer = SimpleImputer(strategy='mean')
df_imputed = imputer.fit_transform(df)
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_imputed)

# # ==============================
# # Preprocessing (Applies  Bahar wala Breast cancer)
# # ==============================

# # Encode categorical labels to numeric
# label_encoder = LabelEncoder()
# labels_encoded = label_encoder.fit_transform(labels)


# Impute missing values
imputer = SimpleImputer(strategy='mean')
df_imputed = imputer.fit_transform(df)

# Scale the imputed dataset
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_imputed)

# Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(df_scaled, labels, test_size=0.2, random_state=42) # rest sabke liya
# X_train, X_test, y_train, y_test = train_test_split(df_scaled, labels_encoded, test_size=0.2, random_state=42) # for bahar wala breast cancer

X_train
y_train
lr = LogisticRegression()
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)
print(y_pred_lr)
y_prob_lr = lr.predict_proba(X_test) if hasattr(lr, 'predict_proba') else None
cm = confusion_matrix(y_test,y_pred_lr)
print(cm)
sns.heatmap(cm, annot = True, cmap = 'Blues' ,fmt='d')
plt.title('Confusion Matrix of Logistic Regression')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

knn = KNeighborsClassifier()
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)
print(y_pred_knn)
y_prob_knn = knn.predict_proba(X_test) if hasattr(knn, 'predict_proba') else None
cm = confusion_matrix(y_test,y_pred_knn)
print(cm)
sns.heatmap(cm, annot = True, cmap = 'Blues' ,fmt='d')
plt.title('Confusion Matrix of KNN')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

tree = DecisionTreeClassifier()
tree.fit(X_train, y_train)
y_pred_tree = tree.predict(X_test)
print(y_pred_tree)
y_prob_tree = tree.predict_proba(X_test) if hasattr(tree, 'predict_proba') else None
cm = confusion_matrix(y_test,y_pred_tree)
print(cm)
sns.heatmap(cm, annot = True, cmap = 'Blues' ,fmt='d')
plt.title('Confusion Matrix of Decision Tree')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

forest = RandomForestClassifier()
forest.fit(X_train, y_train)
y_pred_forest = forest.predict(X_test)
print(y_pred_forest)
y_prob_forest = forest.predict_proba(X_test) if hasattr(forest, 'predict_proba') else None
cm = confusion_matrix(y_test,y_pred_forest)
print(cm)
sns.heatmap(cm, annot = True, cmap = 'Blues' ,fmt='d')
plt.title('Confusion Matrix of Random Forest')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

gr = GradientBoostingClassifier()
gr.fit(X_train, y_train)
y_pred_gr =gr.predict(X_test)
print(y_pred_gr)
y_prob_gr = gr.predict_proba(X_test) if hasattr(gr, 'predict_proba') else None
cm = confusion_matrix(y_test,y_pred_gr)
print(cm)
sns.heatmap(cm, annot = True, cmap = 'Blues' ,fmt='d')
plt.title('Confusion Matrix of Gradient Boost')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

bag = BaggingClassifier(estimator = DecisionTreeClassifier())
bag.fit(X_train, y_train)
y_pred_bag =bag.predict(X_test)
print(y_pred_bag)
y_prob_bag = bag.predict_proba(X_test) if hasattr(bag, 'predict_proba') else None
cm = confusion_matrix(y_test,y_pred_bag)
print(cm)
sns.heatmap(cm, annot = True, cmap = 'Blues' ,fmt='d')
plt.title('Confusion Matrix of Bagging Classifier')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

ada = AdaBoostClassifier()
ada.fit(X_train, y_train)
y_pred_ada =ada.predict(X_test)
print(y_pred_ada)
y_prob_ada = ada.predict_proba(X_test) if hasattr(ada, 'predict_proba') else None
cm = confusion_matrix(y_test,y_pred_ada)
print(cm)
sns.heatmap(cm, annot = True, cmap = 'Blues' ,fmt='d')
plt.title('Confusion Matrix of AdaBoost')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

clf = SVC(probability=True)
clf.fit(X_train, y_train)
y_pred_clf =clf.predict(X_test)
print(y_pred_clf)
y_prob_clf = clf.predict_proba(X_test) if hasattr(clf, 'predict_proba') else None
cm = confusion_matrix(y_test,y_pred_clf)
print(cm)
sns.heatmap(cm, annot = True, cmap = 'Blues' ,fmt='d')
plt.title('Confusion Matrix of SVM')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

bayes = GaussianNB()
bayes.fit(X_train, y_train)
y_pred_bayes =bayes.predict(X_test)
print(y_pred_bayes)
y_prob_bayes = bayes.predict_proba(X_test) if hasattr(bayes, 'predict_proba') else None
cm = confusion_matrix(y_test,y_pred_bayes)
print(cm)
sns.heatmap(cm, annot = True, cmap = 'Blues' ,fmt='d')
plt.title('Confusion Matrix of Naive Bayes')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.show()

models = ['Logistic Regression','KNN', 'Decision Tree', 'Random Forest','Gradient Boost','Bagging Classifier','AdaBoost','SVM','Naive Bayes']

accuracy = [accuracy_score(y_test, y_pred_lr),
            accuracy_score(y_test, y_pred_knn),
            accuracy_score(y_test, y_pred_tree),
            accuracy_score(y_test, y_pred_forest),
            accuracy_score(y_test, y_pred_gr),
            accuracy_score(y_test, y_pred_bag),
            accuracy_score(y_test, y_pred_ada),
            accuracy_score(y_test, y_pred_clf),
            accuracy_score(y_test, y_pred_bayes)]

precision = [precision_score(y_test, y_pred_lr,average='weighted'),
            precision_score(y_test, y_pred_knn,average='weighted'),
            precision_score(y_test, y_pred_tree,average='weighted'),
            precision_score(y_test, y_pred_forest,average='weighted'),
            precision_score(y_test, y_pred_gr,average='weighted'),
            precision_score(y_test, y_pred_bag,average='weighted'),
            precision_score(y_test, y_pred_ada,average='weighted'),
            precision_score(y_test, y_pred_clf,average='weighted'),
            precision_score(y_test, y_pred_bayes,average='weighted')]

recall = [recall_score(y_test, y_pred_lr,average='weighted'),
            recall_score(y_test, y_pred_knn,average='weighted'),
            recall_score(y_test, y_pred_tree,average='weighted'),
            recall_score(y_test, y_pred_forest,average='weighted'),
            recall_score(y_test, y_pred_gr,average='weighted'),
            recall_score(y_test, y_pred_bag,average='weighted'),
            recall_score(y_test, y_pred_ada,average='weighted'),
            recall_score(y_test, y_pred_clf,average='weighted'),
            recall_score(y_test, y_pred_bayes,average='weighted')]

# f1_score = [f1_score(y_test, y_pred_lr,average='weighted'),
#             f1_score(y_test, y_pred_knn,average='weighted'),
#             f1_score(y_test, y_pred_tree,average='weighted'),
#             f1_score(y_test, y_pred_forest,average='weighted'),
#             f1_score(y_test, y_pred_gr,average='weighted'),
#             f1_score(y_test, y_pred_bag,average='weighted'),
#             f1_score(y_test, y_pred_ada,average='weighted'),
#             f1_score(y_test, y_pred_clf,average='weighted'),
#             f1_score(y_test, y_pred_bayes,average='weighted')]

def auc(y_test, y_prob):
  if y_prob is not None:
    if len(np.unique(y_test))>2:
      roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')
    else:
      roc_auc = roc_auc_score(y_test, y_prob[:, 1])
  else:
    roc_auc = 'N/A'
  return roc_auc

auc_roc = [auc(y_test, y_prob_lr),
            auc(y_test, y_prob_knn),
            auc(y_test, y_prob_tree),
            auc(y_test, y_prob_forest),
            auc(y_test, y_prob_gr),
            auc(y_test, y_prob_bag),
            auc(y_test, y_prob_ada),
            auc(y_test, y_prob_clf),
            auc(y_test, y_prob_bayes)]

performance_df = pd.DataFrame({
    "Model" : models,
    "Accuracy" : accuracy,
    "Precision Score" : precision,
    "Recall Score" : recall,
    "F1 Score" : f1_score,
    "AUC-ROC Score" : auc_roc
})

print(performance_df)

performance_df.set_index('Model').plot(kind='bar',figsize=(12,10),color=['red','blue','green','yellow','orange'])
plt.xticks(rotation=45)
plt.title("Metrics")
plt.xlabel('Models')
plt.legend(loc = 'lower right')
plt.show()